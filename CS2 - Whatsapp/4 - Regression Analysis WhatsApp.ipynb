{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f7dabe6f-e2a0-4d81-9743-4f33b45ceb60",
   "metadata": {},
   "source": [
    "# Regression Analysis\n",
    "\n",
    "*Use the \"1 - Create Network and Backbone WhatsApps\" notebook to download and uncompress the data*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "average-anxiety",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from dateutil import rrule\n",
    "from datetime import date, datetime, timedelta\n",
    "import pandas as pd\n",
    "import pickle as pkl\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import fastplot\n",
    "import seaborn as sns\n",
    "import scipy\n",
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "from sklearn import linear_model\n",
    "import itertools\n",
    "from sklearn.model_selection import train_test_split\n",
    "import sklearn.metrics\n",
    "import networkx as nx\n",
    "pd.options.mode.chained_assignment = None "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "confidential-final",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict, Counter\n",
    "\n",
    "def compute_regression(X, Y): \n",
    "    # with sklearn\n",
    "    regr = linear_model.LinearRegression()\n",
    "    regr.fit(X, Y)\n",
    "    # with statsmodels\n",
    "    X_new = sm.add_constant(X) # adding a constant\n",
    "    model = sm.OLS(Y, X_new).fit()\n",
    "    return model, regr\n",
    "\n",
    "\n",
    "\n",
    "def gini(x):\n",
    "    mad = np.abs(np.subtract.outer(x, x)).mean()\n",
    "    rmad = mad/np.mean(x)\n",
    "    g = 0.5 * rmad\n",
    "    return g\n",
    "\n",
    "def extract_variables(df_full, edge_list):\n",
    "    \n",
    "    # \"Timestamp\", \"Snapshot_ID\", \"Group_ID\", \"User_ID\", \"Message_ID\", \"Media_Type\"\n",
    "    user_windows_msg = defaultdict(set)\n",
    "    user_window = defaultdict(set)\n",
    "    msg_first = {}\n",
    "    u2g = defaultdict(set)\n",
    "    g2u = defaultdict(set)\n",
    "    teste = 1\n",
    "    for tup in df_full.itertuples():\n",
    "        t = [1]\n",
    "        win = tup[1].split(\" \")[0]\n",
    "        #win = str(tup[0])\n",
    "        g = tup[2]\n",
    "        u = tup[3]\n",
    "        msg = tup[4]\n",
    "\n",
    "        \n",
    "        user_windows_msg[u].add(win + \" \" + msg)\n",
    "        user_window[u].add(win)\n",
    "        \n",
    "        if msg not in msg_first or msg_first[msg][0]>t:\n",
    "            msg_first[msg] = (t,u)            \n",
    "        u2g[u].add(g)\n",
    "        g2u[g].add(u)    \n",
    "        \n",
    "    \n",
    "    # Number of messages they were the first to post (fresh content)\n",
    "    user_first = Counter()\n",
    "    for msg in msg_first:\n",
    "        user_first[msg_first[msg][1]]+=1    \n",
    "    edge_list[\"u_first_nb\"] = edge_list['u'].apply(lambda e: user_first[e])\n",
    "    edge_list[\"v_first_nb\"] = edge_list['v'].apply(lambda e: user_first[e]) \n",
    "  \n",
    "\n",
    "    #Gini on message to group distribution - Count \n",
    "    df_temp = df_full\n",
    "    df_temp = df_temp.groupby(['User_ID', 'Group_ID'])[\"Group_ID\"].count().reset_index(name=\"Count\")\n",
    "    dict_user_groups = {}\n",
    "    for i, row in df_temp.iterrows():\n",
    "        if row['User_ID'] not in dict_user_groups:\n",
    "            dict_user_groups[row['User_ID']] = {}\n",
    "        dict_user_groups[row['User_ID']][row['Group_ID']] = row['Count']\n",
    "\n",
    "    dict_user_gini = {}\n",
    "    for user, dict_dist in dict_user_groups.items():\n",
    "        dict_user_gini[user] = gini(list(dict_user_groups[user].values()))\n",
    "        \n",
    "    edge_list[\"u_n_gini_count\"] = edge_list['u'].map(dict_user_gini)\n",
    "    edge_list[\"v_n_gini_count\"] = edge_list['v'].map(dict_user_gini)      \n",
    "        \n",
    "\n",
    "    \n",
    "    \n",
    "    #Number of distinct groups u and v have posted\n",
    "    df_temp = df_full\n",
    "    df_temp = df_temp.groupby(['User_ID'])[\"Group_ID\"].nunique().reset_index(name=\"nunique\")\n",
    "    dict_user2nmessages = dict(zip(df_temp['User_ID'],df_temp['nunique']))\n",
    "    \n",
    "    edge_list[\"u_n_unique_group\"] = edge_list['u'].map(dict_user2nmessages)\n",
    "    edge_list[\"v_n_unique_group\"] = edge_list['v'].map(dict_user2nmessages)\n",
    "    \n",
    "    \n",
    "    #Common number of groups u and v have posted\n",
    "    df_temp = df_full\n",
    "    #df_temp = df_temp.groupby(['User_ID','Message_ID'])['Message_ID'].count().reset_index(name=\"count\")\n",
    "    dict_user2messages = df_temp.groupby('User_ID')['Group_ID'].apply(lambda x: list(np.unique(x)))\n",
    "    dict_user2messages = dict_user2messages.to_frame().reset_index()\n",
    "    dict_user2messages = dict(zip(dict_user2messages['User_ID'],dict_user2messages['Group_ID']))\n",
    " \n",
    "    dict_index_value = {}\n",
    "    edge_list['list_u'] = edge_list['u'].map(dict_user2messages)\n",
    "    edge_list['list_v'] = edge_list['v'].map(dict_user2messages)\n",
    "        \n",
    "    for row in edge_list.loc[edge_list.list_u.isnull(), 'list_u'].index:\n",
    "        edge_list.at[row, 'list_u'] = []\n",
    "    for row in edge_list.loc[edge_list.list_v.isnull(), 'list_v'].index:\n",
    "        edge_list.at[row, 'list_v'] = []\n",
    "\n",
    "    edge_list['Common_n_group'] = edge_list[['list_u', 'list_v']].apply(lambda r: len(set(r['list_u']) & set(r['list_v'])), axis=1)\n",
    "    edge_list[\"Common_n_group\"] = edge_list[\"Common_n_group\"].fillna(0)\n",
    "    edge_list[\"Common_n_group\"] = edge_list[\"Common_n_group\"].fillna(0)\n",
    "    del edge_list['list_u']\n",
    "    del edge_list['list_v']\n",
    "    \n",
    "\n",
    "    #Number of messages unique shared by u and v\n",
    "    df_temp = df_full\n",
    "    df_temp = df_temp.groupby(['User_ID'])[\"Message_ID\"].nunique().reset_index(name=\"nunique\")\n",
    "    dict_user2nmessages = dict(zip(df_temp['User_ID'],df_temp['nunique']))\n",
    "    edge_list[\"u_n_unique_msg\"] = edge_list['u'].map(dict_user2nmessages)\n",
    "    edge_list[\"v_n_unique_msg\"] = edge_list['v'].map(dict_user2nmessages)\n",
    "    \n",
    "    \n",
    "    #Number of messages total shared by u and v\n",
    "    df_temp = df_full\n",
    "    df_temp = df_temp.groupby(['User_ID'])[\"Message_ID\"].count().reset_index(name=\"count\")\n",
    "    dict_user2nmessages = dict(zip(df_temp['User_ID'],df_temp['count']))\n",
    "    edge_list[\"u_n_total_msg\"] = edge_list['u'].map(dict_user2nmessages)\n",
    "    edge_list[\"v_n_total_msg\"] = edge_list['v'].map(dict_user2nmessages)\n",
    "\n",
    "    return edge_list\n",
    "\n",
    "def sort_edges(edge_list):\n",
    "    tmp = edge_list.apply(lambda r:(r['u'],r['v'],r['w']) if (r['u'] < r['v']) else (r['v'], r['u'], r['w']), axis=1)       \n",
    "    edge_list = pd.DataFrame(list(tmp), columns=['u', 'v', 'w'])\n",
    "    del tmp\n",
    "    return edge_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "comic-garbage",
   "metadata": {},
   "source": [
    "# Read the data complete network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dressed-occurrence",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "From Sklearn: \n",
      "\n",
      "Intercept: \n",
      " 0.7655192525036638\n",
      "Coefficients: \n",
      " [-0.17043706 -0.21367018 -0.00809859  0.16898989  0.0072726  -0.10446354\n",
      "  0.0256984   0.16157639  0.19108931  0.00655042  0.02170815]\n",
      "R^2: 0.21739345039601154\n",
      "RMSE 2.399\n",
      "NRMSE 1.9801804321118794\n"
     ]
    }
   ],
   "source": [
    "PATH_Data = 'WhatsApp/data/'\n",
    "PATH_Networks = 'WhatsApp/networks/'\n",
    "\n",
    "k = 'October'\n",
    "\n",
    "df_full = pd.read_csv('WhatsApp/data/'+'whatsapp_messages.csv', names=[\"Timestamp\", \"Snapshot_ID\", \"Group_ID\", \"User_ID\", \n",
    "\n",
    "                                                                       \"Message_ID\", \"Media_Type\", \"Misinformation\"])\n",
    "df_full = df_full[df_full['Snapshot_ID'].isin([40,41,42,43])]\n",
    "\n",
    "df_full['Timestamp'] =  pd.to_datetime(df_full['Timestamp'], errors='coerce')\n",
    "df_full['Timestamp'] = df_full['Timestamp'].apply(lambda x: x.strftime('%Y-%m-%d %H')if not pd.isnull(x) else '')\n",
    "\n",
    "edge_list = pd.read_csv(PATH_Networks+k+'.edgelist', \n",
    "                                 names=['u', 'v', 'w', 'u_id', 'v_id'], header=None, delimiter=' ')\n",
    "\n",
    "\n",
    "edge_list = sort_edges(edge_list)\n",
    "edge_list = extract_variables(df_full[[\"Timestamp\", \"Group_ID\", \"User_ID\", \"Message_ID\", \"Media_Type\", \"Misinformation\"]], \n",
    "                              edge_list[['u', 'v', 'w']])\n",
    "\n",
    "X = np.sqrt(edge_list[['u_first_nb', 'v_first_nb', 'u_n_gini_count',\n",
    "       'v_n_gini_count', 'u_n_unique_group', 'v_n_unique_group',\n",
    "       'Common_n_group', 'u_n_unique_msg', 'v_n_unique_msg', 'u_n_total_msg',\n",
    "       'v_n_total_msg']])  \n",
    "\n",
    "Y = np.sqrt(edge_list['w'])\n",
    "\n",
    "model, model_2 = compute_regression(X, Y)\n",
    "\n",
    "edge_list['y'] = Y\n",
    "edge_list['y_hat'] = model_2.predict(X)\n",
    "edge_list['res'] = (Y-edge_list['y_hat'])\n",
    "\n",
    "print(\"From Sklearn: \\n\")\n",
    "print('Intercept: \\n', model_2.intercept_)\n",
    "print('Coefficients: \\n', model_2.coef_)\n",
    "print('R^2: {0}'.format(model_2.score(X, Y)))\n",
    "RMSE = round(sklearn.metrics.mean_squared_error((edge_list['y'])**2, (edge_list['y_hat'])**2, squared=False),3)\n",
    "print('RMSE', RMSE)\n",
    "print('NRMSE', RMSE/np.mean(edge_list['y']))\n",
    "PATH_Regression = 'WhatsApp/regression/'+k+'-'\n",
    "pkl.dump(edge_list, open(PATH_Regression+'edge_list_Original.pickle', 'wb'), protocol=pkl.HIGHEST_PROTOCOL)\n",
    "pkl.dump(model, open(PATH_Regression+'stats_Original.pickle', 'wb'), protocol=pkl.HIGHEST_PROTOCOL)\n",
    "pkl.dump(model_2, open(PATH_Regression+'sklearn_Original.pickle', 'wb'), protocol=pkl.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "wicked-phone",
   "metadata": {},
   "source": [
    "# Threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "aging-posting",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------- 99.5 ---------------------\n",
      "From Sklearn: \n",
      "\n",
      "Intercept: \n",
      " 3.339794458553567\n",
      "Coefficients: \n",
      " [-0.13705417 -0.11937215  0.06864148  0.06106281  0.23484356 -0.13940911\n",
      "  0.03079975  0.21249077  0.11330023 -0.05741293  0.02888879]\n",
      "R^2: 0.38263520721467703\n",
      "RMSE 4.181\n",
      "NRMSE 0.8769231570296459\n",
      "--------------------- 99.0 ---------------------\n",
      "From Sklearn: \n",
      "\n",
      "Intercept: \n",
      " 3.544265241486751\n",
      "Coefficients: \n",
      " [-0.112705   -0.11723914  0.19414995 -0.04846251 -0.08420458 -0.0029114\n",
      "  0.0063541   0.12802759  0.09617298 -0.00177959  0.03650933]\n",
      "R^2: 0.31186327963310834\n",
      "RMSE 3.693\n",
      "NRMSE 0.8215644595702493\n",
      "--------------------- 95.0 ---------------------\n",
      "From Sklearn: \n",
      "\n",
      "Intercept: \n",
      " 2.941448532740647\n",
      "Coefficients: \n",
      " [-0.25045638 -0.3004889   0.27639624  0.2451982  -0.40588008 -0.30101465\n",
      " -0.03190937  0.15183221  0.16166222  0.08509942  0.12565884]\n",
      "R^2: 0.22343987998731252\n",
      "RMSE 4.686\n",
      "NRMSE 1.3626698586867532\n",
      "--------------------- 90.0 ---------------------\n",
      "From Sklearn: \n",
      "\n",
      "Intercept: \n",
      " 2.100719074264117\n",
      "Coefficients: \n",
      " [-0.32640881 -0.37579499  0.31908762  0.36366637 -0.38124093 -0.1187019\n",
      " -0.02030539  0.22116985  0.27565596  0.08131711  0.07855759]\n",
      "R^2: 0.24858963306593485\n",
      "RMSE 4.715\n",
      "NRMSE 1.658019196809264\n",
      "--------------------- 80.0 ---------------------\n",
      "From Sklearn: \n",
      "\n",
      "Intercept: \n",
      " 1.7548890988176402\n",
      "Coefficients: \n",
      " [-0.34368248 -0.39418741  0.222242    0.39169295 -0.21871218 -0.1719553\n",
      " -0.01509366  0.2692234   0.29082958  0.04833379  0.0766124 ]\n",
      "R^2: 0.2421566259097777\n",
      "RMSE 4.621\n",
      "NRMSE 1.818498966385143\n"
     ]
    }
   ],
   "source": [
    "k = 'October'\n",
    "\n",
    "for percentile in [0.995, 0.99, 0.95, 0.9, 0.8]:\n",
    "    print('---------------------', percentile*100, '---------------------')\n",
    "    PATH_Networks = 'WhatsApp/networks/'\n",
    "    PATH_Regression = 'WhatsApp/regression/'+k+'-'\n",
    "    edge_list = pd.read_csv(PATH_Networks+k+'.edgelist', \n",
    "                                     names=['u', 'v', 'w', 'u_id', 'v_id'], header=None, delimiter=' ')\n",
    "    edge_list = sort_edges(edge_list)\n",
    "    dist_weights = list(edge_list['w'])\n",
    "    threshold = np.percentile(dist_weights, (percentile)*100)\n",
    "    edge_list = edge_list[edge_list['w'] > threshold]\n",
    "    \n",
    "    df_full = pd.read_csv('WhatsApp/data/'+'whatsapp_messages.csv', names=[\"Timestamp\", \"Snapshot_ID\", \"Group_ID\", \"User_ID\", \n",
    "                                                                           \"Message_ID\", \"Media_Type\", \"Misinformation\"])\n",
    "\n",
    "    df_full = df_full[df_full['Snapshot_ID'].isin([40,41,42,43])]\n",
    "\n",
    "    df_full['Timestamp'] =  pd.to_datetime(df_full['Timestamp'], errors='coerce')\n",
    "    df_full['Timestamp'] = df_full['Timestamp'].apply(lambda x: x.strftime('%Y-%m-%d %H')if not pd.isnull(x) else '')\n",
    "    edge_list = extract_variables(df_full[[\"Timestamp\", \"Group_ID\", \"User_ID\", \"Message_ID\", \"Media_Type\", \"Misinformation\"]], edge_list[['u', 'v', 'w']])\n",
    "    del df_full\n",
    "    X = np.sqrt(edge_list[['u_first_nb', 'v_first_nb', 'u_n_gini_count',\n",
    "           'v_n_gini_count', 'u_n_unique_group', 'v_n_unique_group',\n",
    "           'Common_n_group', 'u_n_unique_msg', 'v_n_unique_msg', 'u_n_total_msg',\n",
    "           'v_n_total_msg']])\n",
    "\n",
    "    Y = np.sqrt(edge_list['w'])\n",
    "    model, model_2 = compute_regression(X, Y)\n",
    "\n",
    "    edge_list['y'] = Y\n",
    "    edge_list['y_hat'] = model_2.predict(X)\n",
    "    edge_list['res'] = (Y-edge_list['y_hat'])\n",
    "\n",
    "    print(\"From Sklearn: \\n\")\n",
    "    print('Intercept: \\n', model_2.intercept_)\n",
    "    print('Coefficients: \\n', model_2.coef_)\n",
    "    print('R^2: {0}'.format(model_2.score(X, Y)))\n",
    "    RMSE = round(sklearn.metrics.mean_squared_error((edge_list['y'])**2, (edge_list['y_hat'])**2, squared=False),3)\n",
    "    print('RMSE', RMSE)\n",
    "    print('NRMSE', RMSE/np.mean(edge_list['y']))\n",
    "    PATH_Regression = 'WhatsApp/regression/'+k+'-'+str(percentile)+'-'\n",
    "    pkl.dump(edge_list, open(PATH_Regression+'edge_list_threshold.pickle', 'wb'), protocol=pkl.HIGHEST_PROTOCOL)\n",
    "    pkl.dump(model, open(PATH_Regression+'stats_threshold.pickle', 'wb'), protocol=pkl.HIGHEST_PROTOCOL)\n",
    "    pkl.dump(model_2, open(PATH_Regression+'sklearn_threshold.pickle', 'wb'), protocol=pkl.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ready-number",
   "metadata": {},
   "source": [
    "# DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "first-nutrition",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alpha 0.0010000000000000009\n",
      "From Sklearn: \n",
      "\n",
      "Intercept: \n",
      " 3.0981496536930653\n",
      "Coefficients: \n",
      " [-0.28203103 -0.3224524   0.16855976  0.3203038   0.09934009 -0.44503093\n",
      " -0.13280925  0.26228783  0.20393021  0.0187813   0.10968801]\n",
      "R^2: 0.33472203757331\n",
      "RMSE 6.04\n",
      "NRMSE 1.319845483878308\n",
      "alpha 0.0050000000000000044\n",
      "From Sklearn: \n",
      "\n",
      "Intercept: \n",
      " 2.8612421427661836\n",
      "Coefficients: \n",
      " [-0.31127179 -0.35621129  0.14209009  0.33118934 -0.11175876 -0.28436353\n",
      " -0.10614317  0.25960325  0.25680709  0.03792291  0.08836963]\n",
      "R^2: 0.30445781345315015\n",
      "RMSE 5.403\n",
      "NRMSE 1.3074742113023952\n",
      "alpha 0.010000000000000009\n",
      "From Sklearn: \n",
      "\n",
      "Intercept: \n",
      " 2.7981449543557053\n",
      "Coefficients: \n",
      " [-0.31541262 -0.39971827  0.11718093  0.25455782 -0.15169991 -0.30828171\n",
      " -0.09944905  0.25427428  0.26446251  0.0441881   0.11370294]\n",
      "R^2: 0.31560006175323196\n",
      "RMSE 5.159\n",
      "NRMSE 1.3177102966783056\n",
      "alpha 0.050000000000000044\n",
      "From Sklearn: \n",
      "\n",
      "Intercept: \n",
      " 2.280696455097207\n",
      "Coefficients: \n",
      " [-0.38340385 -0.44353304  0.22032228  0.25246542 -0.3055418  -0.17421317\n",
      " -0.04220038  0.27766012  0.31237002  0.07730494  0.10051237]\n",
      "R^2: 0.35005215672583756\n",
      "RMSE 4.795\n",
      "NRMSE 1.4724790754139077\n",
      "alpha 0.09999999999999998\n",
      "From Sklearn: \n",
      "\n",
      "Intercept: \n",
      " 1.7158345700699136\n",
      "Coefficients: \n",
      " [-0.40405436 -0.47094874  0.1734222   0.23492144 -0.153535   -0.08863293\n",
      " -0.03503365  0.32338968  0.35898149  0.0497137   0.07773234]\n",
      "R^2: 0.34426645451501203\n",
      "RMSE 4.685\n",
      "NRMSE 1.6303313477920784\n"
     ]
    }
   ],
   "source": [
    "k = 'October'\n",
    "backbone = 'DF'\n",
    "\n",
    "for confidence in [0.999, 0.995, 0.99, 0.95, 0.9]:\n",
    "    print('alpha', 1-confidence)\n",
    "    \n",
    "    PATH_Data = 'WhatsApp/data/'\n",
    "    type_network = 'DF'\n",
    "    Path_Networks = 'WhatsApp/backbones/df/'+str(k)+'.edgelist'\n",
    "    Path_Communities = 'WhatsApp/communities/'+type_network+str(k)+'-'+str(confidence)+'.pkl'\n",
    "    edge_list = pd.read_csv(Path_Networks, sep=',', names=['u', 'v', 'w','score','var'])\n",
    "    edge_list = edge_list[edge_list['score'] > confidence]\n",
    "    edge_list = sort_edges(edge_list)\n",
    "\n",
    "    df_full = pd.read_csv(PATH_Data+'whatsapp_messages.csv', names=[\"Timestamp\", \"Snapshot_ID\", \"Group_ID\", \n",
    "                                                                    \"User_ID\",\"Message_ID\", \"Media_Type\", \"Misinformation\"])\n",
    "\n",
    "    df_full = df_full[df_full['Snapshot_ID'].isin([40,41,42,43])]\n",
    "\n",
    "    edge_list = extract_variables(df_full[[\"Timestamp\", \"Group_ID\", \"User_ID\", \"Message_ID\", \"Media_Type\", \"Misinformation\"]], edge_list[['u', 'v', 'w']])\n",
    "    del df_full\n",
    "\n",
    "    X = np.sqrt(edge_list[['u_first_nb', 'v_first_nb', 'u_n_gini_count',\n",
    "           'v_n_gini_count', 'u_n_unique_group', 'v_n_unique_group',\n",
    "           'Common_n_group', 'u_n_unique_msg', 'v_n_unique_msg', 'u_n_total_msg',\n",
    "           'v_n_total_msg']])\n",
    "\n",
    "    Y = np.sqrt(edge_list['w'])\n",
    "\n",
    "    model, model_2 = compute_regression(X, Y)\n",
    "\n",
    "    edge_list['y'] = Y\n",
    "    edge_list['y_hat'] = model_2.predict(X)\n",
    "    edge_list['res'] = (Y-edge_list['y_hat'])\n",
    "\n",
    "    print(\"From Sklearn: \\n\")\n",
    "    print('Intercept: \\n', model_2.intercept_)\n",
    "    print('Coefficients: \\n', model_2.coef_)\n",
    "    print('R^2: {0}'.format(model_2.score(X, Y)))\n",
    "    RMSE = round(sklearn.metrics.mean_squared_error((edge_list['y'])**2, (edge_list['y_hat'])**2, squared=False),3)\n",
    "    print('RMSE', RMSE)\n",
    "    print('NRMSE', RMSE/np.mean(edge_list['y']))\n",
    "    PATH_Regression = 'WhatsApp/regression/'+k+'-'+str(confidence)+'-'\n",
    "    pkl.dump(edge_list, open(PATH_Regression+'edge_list_df.pickle', 'wb'), protocol=pkl.HIGHEST_PROTOCOL)\n",
    "    pkl.dump(model, open(PATH_Regression+'stats_df.pickle', 'wb'), protocol=pkl.HIGHEST_PROTOCOL)\n",
    "    pkl.dump(model_2, open(PATH_Regression+'sklearn_df.pickle', 'wb'), protocol=pkl.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "filled-gibraltar",
   "metadata": {},
   "source": [
    "## Polya Urn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "worst-sleeping",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alpha 0.001\n",
      "From Sklearn: \n",
      "\n",
      "Intercept: \n",
      " 3.4207195399274744\n",
      "Coefficients: \n",
      " [-0.23148195 -0.26847242  0.1748846   0.25917278 -0.11035613 -0.3888202\n",
      " -0.12842782  0.19133267  0.15265519  0.03292685  0.10476087]\n",
      "R^2: 0.231992398796787\n",
      "RMSE 4.705\n",
      "NRMSE 1.1159698704639909\n",
      "Alpha 0.005\n",
      "From Sklearn: \n",
      "\n",
      "Intercept: \n",
      " 3.1008199860469485\n",
      "Coefficients: \n",
      " [-0.27916311 -0.32914996  0.30213925  0.22871096 -0.29132845 -0.26900803\n",
      " -0.09773326  0.20106832  0.19815515  0.06321392  0.11240386]\n",
      "R^2: 0.2782400051883025\n",
      "RMSE 4.696\n",
      "NRMSE 1.204500696947734\n",
      "Alpha 0.01\n",
      "From Sklearn: \n",
      "\n",
      "Intercept: \n",
      " 3.0312916217581076\n",
      "Coefficients: \n",
      " [-0.29229263 -0.36733658  0.32275128  0.22161364 -0.39077849 -0.2469688\n",
      " -0.04857034  0.18741545  0.22418516  0.08487184  0.11910071]\n",
      "R^2: 0.2941535732895162\n",
      "RMSE 4.72\n",
      "NRMSE 1.2639619226453136\n",
      "Alpha 0.05\n",
      "From Sklearn: \n",
      "\n",
      "Intercept: \n",
      " 2.5265990597613195\n",
      "Coefficients: \n",
      " [-0.34204177 -0.38563717  0.26352859  0.22989494 -0.33545515 -0.24039888\n",
      " -0.04399401  0.24045692  0.23976882  0.07730015  0.11973297]\n",
      "R^2: 0.30157109098729296\n",
      "RMSE 4.728\n",
      "NRMSE 1.4364103757589939\n",
      "Alpha 0.1\n",
      "From Sklearn: \n",
      "\n",
      "Intercept: \n",
      " 2.1326987690296533\n",
      "Coefficients: \n",
      " [-0.36257833 -0.40004825  0.24829149  0.2756526  -0.27760344 -0.14720458\n",
      " -0.04869163  0.28005823  0.28729203  0.05725057  0.08763874]\n",
      "R^2: 0.30317578677260515\n",
      "RMSE 4.692\n",
      "NRMSE 1.5293472732035573\n"
     ]
    }
   ],
   "source": [
    "k = 'October' \n",
    "backbone = 'Polya'\n",
    "\n",
    "for alpha in [0.001, 0.005, 0.01, 0.05, 0.1]:\n",
    "    print(\"Alpha\", alpha)\n",
    "    PATH_Data = 'WhatsApp/data/'\n",
    "    type_network = 'polya'\n",
    "    Path_Networks = 'WhatsApp/backbones/polya/'+str(k)+'.edgelist'\n",
    "    Path_Communities = 'WhatsApp/communities/'+type_network+str(k)+'-'+str(alpha)+'.pkl'\n",
    "    edge_list = pd.read_csv(Path_Networks, sep=',', names=['u', 'v', 'w', 'p_value'])\n",
    "    edge_list = edge_list[edge_list['p_value'] < alpha]\n",
    "    edge_list = sort_edges(edge_list)\n",
    "\n",
    "    df_full = pd.read_csv(PATH_Data+'whatsapp_messages.csv', names=[\"Timestamp\", \"Snapshot_ID\", \"Group_ID\", \n",
    "                                                                    \"User_ID\",\"Message_ID\", \"Media_Type\", \"Misinformation\"])\n",
    "    df_full = df_full[df_full['Snapshot_ID'].isin([40,41,42,43])]\n",
    "\n",
    "\n",
    "    edge_list = extract_variables(df_full[[\"Timestamp\", \"Group_ID\", \"User_ID\", \"Message_ID\", \"Media_Type\", \"Misinformation\"]], \n",
    "                                  edge_list[['u', 'v', 'w']])\n",
    "    del df_full\n",
    "    X = np.sqrt(edge_list[['u_first_nb', 'v_first_nb', 'u_n_gini_count',\n",
    "           'v_n_gini_count', 'u_n_unique_group', 'v_n_unique_group',\n",
    "           'Common_n_group', 'u_n_unique_msg', 'v_n_unique_msg', 'u_n_total_msg',\n",
    "           'v_n_total_msg']])\n",
    "\n",
    "    Y = np.sqrt(edge_list['w'])\n",
    "\n",
    "\n",
    "    model, model_2 = compute_regression(X, Y)\n",
    "\n",
    "    edge_list['y'] = Y\n",
    "    edge_list['y_hat'] = model_2.predict(X)\n",
    "    edge_list['res'] = (Y-edge_list['y_hat'])\n",
    "\n",
    "    print(\"From Sklearn: \\n\")\n",
    "    print('Intercept: \\n', model_2.intercept_)\n",
    "    print('Coefficients: \\n', model_2.coef_)\n",
    "    print('R^2: {0}'.format(model_2.score(X, Y)))\n",
    "    RMSE = round(sklearn.metrics.mean_squared_error((edge_list['y'])**2, (edge_list['y_hat'])**2, squared=False),3)\n",
    "    print('RMSE', RMSE)\n",
    "    print('NRMSE', RMSE/np.mean(edge_list['y']))\n",
    "    PATH_Regression = 'WhatsApp/regression/'+k+'-'+str(alpha)+'-'\n",
    "    pkl.dump(edge_list, open(PATH_Regression+'edge_list_polya.pickle', 'wb'), protocol=pkl.HIGHEST_PROTOCOL)\n",
    "    pkl.dump(model, open(PATH_Regression+'stats_polya.pickle', 'wb'), protocol=pkl.HIGHEST_PROTOCOL)\n",
    "    pkl.dump(model_2, open(PATH_Regression+'sklearn_polya.pickle', 'wb'), protocol=pkl.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "framed-accessory",
   "metadata": {},
   "source": [
    "# HSS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "native-nylon",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------- 99.5 ---------------------\n",
      "From Sklearn: \n",
      "\n",
      "Intercept: \n",
      " 0.8251187365523356\n",
      "Coefficients: \n",
      " [-0.06145252 -0.08940052  0.19615715  0.12753689  0.00071718  0.00102439\n",
      "  0.07827933  0.08856515  0.11840221 -0.01279835 -0.00966493]\n",
      "R^2: 0.36776678594658607\n",
      "RMSE 1.142\n",
      "NRMSE 0.8970918327779656\n",
      "--------------------- 99.0 ---------------------\n",
      "From Sklearn: \n",
      "\n",
      "Intercept: \n",
      " 0.9112705364705904\n",
      "Coefficients: \n",
      " [-0.0908705  -0.12158469  0.24130821 -0.02485327 -0.1312388   0.0093325\n",
      "  0.08966923  0.07347271  0.15534758  0.02644845 -0.01252932]\n",
      "R^2: 0.2970414804704392\n",
      "RMSE 1.867\n",
      "NRMSE 1.3614866895962991\n",
      "--------------------- 95.0 ---------------------\n",
      "From Sklearn: \n",
      "\n",
      "Intercept: \n",
      " -0.9204596780422007\n",
      "Coefficients: \n",
      " [-0.37077603 -0.50254835  0.15694942 -0.00848594  0.29301019  0.32306233\n",
      "  0.38252477  0.41332994  0.57253629 -0.03858256 -0.05416981]\n",
      "R^2: 0.4404995269556562\n",
      "RMSE 4.157\n",
      "NRMSE 2.717633828968926\n",
      "--------------------- 90.0 ---------------------\n",
      "From Sklearn: \n",
      "\n",
      "Intercept: \n",
      " -0.7835634369534561\n",
      "Coefficients: \n",
      " [-0.36656242 -0.52310574  0.08699251  0.0227432   0.24121962  0.29957422\n",
      "  0.24940029  0.40136693  0.58950142 -0.02683521 -0.05252756]\n",
      "R^2: 0.46926198502156047\n",
      "RMSE 3.71\n",
      "NRMSE 2.5649733687693375\n",
      "--------------------- 80.0 ---------------------\n",
      "From Sklearn: \n",
      "\n",
      "Intercept: \n",
      " -0.1809972009271048\n",
      "Coefficients: \n",
      " [-0.34630486 -0.53239669  0.0540979   0.05955392  0.15767833  0.20428409\n",
      "  0.1118123   0.35874307  0.56705483 -0.01379584 -0.0309901 ]\n",
      "R^2: 0.48302515880825114\n",
      "RMSE 3.37\n",
      "NRMSE 2.4029923640985973\n"
     ]
    }
   ],
   "source": [
    "k = 'October' \n",
    "backbone = 'HSS'\n",
    "\n",
    "for percentile in [0.995, 0.99, 0.95, 0.9, 0.8]:\n",
    "    percentile = percentile*100\n",
    "    print('---------------------', percentile, '---------------------')\n",
    "    PATH_Data = 'WhatsApp/data/'\n",
    "    type_network = 'HSS'\n",
    "    Path_Networks = 'WhatsApp/backbones/hss/'+str(k)+'.edgelist'\n",
    "    edge_list = pd.read_csv(Path_Networks, sep=',',  names=['u', 'v', 'w', 'score'])\n",
    "    value = np.percentile(list(edge_list['score']),percentile)\n",
    "    edge_list = edge_list[edge_list['score'] > value]\n",
    "    edge_list = sort_edges(edge_list)\n",
    "\n",
    "    df_full = pd.read_csv(PATH_Data+'whatsapp_messages.csv', names=[\"Timestamp\", \"Snapshot_ID\", \"Group_ID\", \n",
    "                                                                \"User_ID\",\"Message_ID\", \"Media_Type\", \"Misinformation\"])\n",
    "\n",
    "    df_full = df_full[df_full['Snapshot_ID'].isin([40,41,42,43])]\n",
    "\n",
    "\n",
    "    edge_list = extract_variables(df_full[[\"Timestamp\", \"Group_ID\", \"User_ID\", \"Message_ID\", \"Media_Type\", \"Misinformation\"]], \n",
    "                                  edge_list[['u', 'v', 'w']])\n",
    "    del df_full\n",
    "    \n",
    "    X = np.sqrt(edge_list[['u_first_nb', 'v_first_nb', 'u_n_gini_count',\n",
    "       'v_n_gini_count', 'u_n_unique_group', 'v_n_unique_group',\n",
    "       'Common_n_group', 'u_n_unique_msg', 'v_n_unique_msg', 'u_n_total_msg',\n",
    "       'v_n_total_msg']])\n",
    "\n",
    "    Y = np.sqrt(edge_list['w'])\n",
    "\n",
    "\n",
    "    model, model_2 = compute_regression(X, Y)\n",
    "\n",
    "    edge_list['y'] = Y\n",
    "    edge_list['y_hat'] = model_2.predict(X)\n",
    "    edge_list['res'] = (Y-edge_list['y_hat'])\n",
    "\n",
    "    print(\"From Sklearn: \\n\")\n",
    "    print('Intercept: \\n', model_2.intercept_)\n",
    "    print('Coefficients: \\n', model_2.coef_)\n",
    "    print('R^2: {0}'.format(model_2.score(X, Y)))\n",
    "    RMSE = round(sklearn.metrics.mean_squared_error((edge_list['y'])**2, (edge_list['y_hat'])**2, squared=False),3)\n",
    "    print('RMSE', RMSE)\n",
    "    print('NRMSE', RMSE/np.mean(edge_list['y']))\n",
    "    PATH_Regression = 'WhatsApp/regression/'+k+'-'+str(percentile)+'-'\n",
    "    pkl.dump(edge_list, open(PATH_Regression+'edge_list_hss.pickle', 'wb'), protocol=pkl.HIGHEST_PROTOCOL)\n",
    "    pkl.dump(model, open(PATH_Regression+'stats_hss.pickle', 'wb'), protocol=pkl.HIGHEST_PROTOCOL)\n",
    "    pkl.dump(model_2, open(PATH_Regression+'sklearn_hss.pickle', 'wb'), protocol=pkl.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ahead-strain",
   "metadata": {},
   "source": [
    "# Recast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "laden-studio",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------- 0.001 --------\n",
      "From Sklearn: \n",
      "\n",
      "Intercept: \n",
      " 2.551735137800221\n",
      "Coefficients: \n",
      " [-0.56071445 -0.53260566  0.53741481  1.00036152 -1.2176865  -0.34825718\n",
      "  0.56928499  0.3943077   0.42544481  0.13951629  0.09462757]\n",
      "R^2: 0.34435207873276763\n",
      "RMSE 8.778\n",
      "NRMSE 2.0695175371637005\n",
      "-------- 0.005 --------\n",
      "From Sklearn: \n",
      "\n",
      "Intercept: \n",
      " 2.551735137800221\n",
      "Coefficients: \n",
      " [-0.56071445 -0.53260566  0.53741481  1.00036152 -1.2176865  -0.34825718\n",
      "  0.56928499  0.3943077   0.42544481  0.13951629  0.09462757]\n",
      "R^2: 0.34435207873276763\n",
      "RMSE 8.778\n",
      "NRMSE 2.0695175371637005\n",
      "-------- 0.01 --------\n",
      "From Sklearn: \n",
      "\n",
      "Intercept: \n",
      " 2.551735137800221\n",
      "Coefficients: \n",
      " [-0.56071445 -0.53260566  0.53741481  1.00036152 -1.2176865  -0.34825718\n",
      "  0.56928499  0.3943077   0.42544481  0.13951629  0.09462757]\n",
      "R^2: 0.34435207873276763\n",
      "RMSE 8.778\n",
      "NRMSE 2.0695175371637005\n",
      "-------- 0.05 --------\n",
      "From Sklearn: \n",
      "\n",
      "Intercept: \n",
      " 2.8088672623436657\n",
      "Coefficients: \n",
      " [-0.38298833 -0.47365429  0.06143915  0.19812889 -0.56995411 -0.39384852\n",
      "  0.01243474  0.26510381  0.26157305  0.09194157  0.17299956]\n",
      "R^2: 0.22666267739438184\n",
      "RMSE 7.044\n",
      "NRMSE 1.9767998047868578\n",
      "-------- 0.1 --------\n",
      "From Sklearn: \n",
      "\n",
      "Intercept: \n",
      " 2.8088672623436657\n",
      "Coefficients: \n",
      " [-0.38298833 -0.47365429  0.06143915  0.19812889 -0.56995411 -0.39384852\n",
      "  0.01243474  0.26510381  0.26157305  0.09194157  0.17299956]\n",
      "R^2: 0.22666267739438184\n",
      "RMSE 7.044\n",
      "NRMSE 1.9767998047868578\n"
     ]
    }
   ],
   "source": [
    "PATH_Networks = 'WhatsApp/networks/'\n",
    "PATH_Backbones = 'WhatsApp/backbones/recast/' \n",
    "k ='October'\n",
    "for alpha in [0.001, 0.005,0.01, 0.05, 0.1]:\n",
    "    print('--------', alpha, '--------')\n",
    "    edge_list = pd.read_csv('WhatsApp/backbones/recast/October-'+str(alpha)+'.edgelist', delimiter=' ')\n",
    "    edge_list = edge_list[['u','v', 'w']]\n",
    "    edge_list = sort_edges(edge_list)\n",
    "    PATH_Data = 'WhatsApp/data/'\n",
    "\n",
    "    df_full = pd.read_csv(PATH_Data+'whatsapp_messages.csv', names=[\"Timestamp\", \"Snapshot_ID\", \"Group_ID\", \n",
    "                                                                    \"User_ID\",\"Message_ID\", \"Media_Type\", \"Misinformation\"])\n",
    "\n",
    "\n",
    "\n",
    "    df_full = df_full[df_full['Snapshot_ID'].isin([40,41,42,43])]\n",
    "    edge_list = extract_variables(df_full[[\"Timestamp\", \"Group_ID\", \"User_ID\", \"Message_ID\", \"Media_Type\", \"Misinformation\"]], edge_list[['u', 'v', 'w']])\n",
    "    del df_full\n",
    "    \n",
    "    X = np.sqrt(edge_list[['u_first_nb', 'v_first_nb', 'u_n_gini_count',\n",
    "       'v_n_gini_count', 'u_n_unique_group', 'v_n_unique_group',\n",
    "       'Common_n_group', 'u_n_unique_msg', 'v_n_unique_msg', 'u_n_total_msg',\n",
    "       'v_n_total_msg']])\n",
    "\n",
    "    Y = np.sqrt(edge_list['w'])\n",
    "\n",
    "\n",
    "    model, model_2 = compute_regression(X, Y)\n",
    "\n",
    "    edge_list['y'] = Y\n",
    "    edge_list['y_hat'] = model_2.predict(X)\n",
    "    edge_list['res'] = (Y-edge_list['y_hat'])\n",
    "\n",
    "    print(\"From Sklearn: \\n\")\n",
    "    print('Intercept: \\n', model_2.intercept_)\n",
    "    print('Coefficients: \\n', model_2.coef_)\n",
    "    print('R^2: {0}'.format(model_2.score(X, Y)))\n",
    "    RMSE = round(sklearn.metrics.mean_squared_error((edge_list['y'])**2, (edge_list['y_hat'])**2, squared=False),3)\n",
    "    print('RMSE', RMSE)\n",
    "    print('NRMSE', RMSE/np.mean(edge_list['y']))\n",
    "    \n",
    "    PATH_Regression = 'WhatsApp/regression/'+k+'-'+str(alpha)+'-'\n",
    "    pkl.dump(edge_list, open(PATH_Regression+'edge_list_recast.pickle', 'wb'), protocol=pkl.HIGHEST_PROTOCOL)\n",
    "    pkl.dump(model, open(PATH_Regression+'stats_recast.pickle', 'wb'), protocol=pkl.HIGHEST_PROTOCOL)\n",
    "    pkl.dump(model_2, open(PATH_Regression+'sklearn_recast.pickle', 'wb'), protocol=pkl.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "enormous-insider",
   "metadata": {},
   "source": [
    "# Analysis of the 5 models\n",
    "- Complete Network\n",
    "- DF\n",
    "- Polya\n",
    "- HSS\n",
    "- Threshold\n",
    "- Recast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "constitutional-violation",
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 'October'\n",
    "#Paramters defined as explained at the paper\n",
    "threshold = 0.950\n",
    "df = 0.95 \n",
    "polya = 0.05\n",
    "hss = 95.0\n",
    "recast = 0.05\n",
    "\n",
    "dict_models = {'Original':'',  'threshold':threshold, 'df':df, 'hss':hss, 'polya':polya, 'recast':recast}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ideal-museum",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original\n",
      "threshold\n",
      "df\n",
      "hss\n",
      "polya\n",
      "recast\n"
     ]
    }
   ],
   "source": [
    "dict_models_user_data = dict()\n",
    "for model, parameter in dict_models.items():\n",
    "    print(model)\n",
    "    if model == \"Original\":\n",
    "        PATH_Regression = 'WhatsApp/regression/'+k+'-'+str(parameter)\n",
    "    else:\n",
    "        PATH_Regression = 'WhatsApp/regression/'+k+'-'+str(parameter)+'-'\n",
    "    dict_models_user_data[model] = pkl.load(open(PATH_Regression+'edge_list_'+model+'.pickle', 'rb'))\n",
    "    dict_models_user_data[model] = dict_models_user_data[model].set_index(['u','v'])\n",
    "\n",
    "df_full = pd.read_csv('WhatsApp/data/'+'whatsapp_messages.csv', names=[\"Timestamp\", \"Snapshot_ID\", \"Group_ID\", \"User_ID\", \n",
    "                                                                       \"Message_ID\", \"Media_Type\", \"Misinformation\"])\n",
    "\n",
    "df_full = df_full[df_full['Snapshot_ID'].isin([40,41,42,43])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "impossible-touch",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = list(set(dict_models_user_data['threshold'].index) & \n",
    "           set(dict_models_user_data['polya'].index) & \n",
    "           set(dict_models_user_data['df'].index) & \n",
    "                set(dict_models_user_data['hss'].index) &\n",
    "                set(dict_models_user_data['recast'].index))\n",
    "#del dict_models['hss']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "foreign-kansas",
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH_Regression = 'WhatsApp/regression/'+k+'-'\n",
    "idx_train, idx_test = train_test_split(idx, test_size=0.2, random_state=2021)\n",
    "pkl.dump(idx, open(PATH_Regression+'set_common_edge.pickle', 'wb'), protocol=pkl.HIGHEST_PROTOCOL)\n",
    "pkl.dump(idx_train, open(PATH_Regression+'set_common_edge_train.pickle', 'wb'), protocol=pkl.HIGHEST_PROTOCOL)\n",
    "pkl.dump(idx_test, open(PATH_Regression+'set_common_edge_test.pickle', 'wb'), protocol=pkl.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "studied-eagle",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------\n",
      "Model Original\n",
      "R^2 Complete: 0.21739345039601154\n",
      "RMSE Complete: 2.399\n",
      "NRMSE Complete: 1.3428153838360815\n",
      "R^2 Train: 0.2147627076428824\n",
      "RMSE Train: 2.367\n",
      "NRMSE Train: 1.3313998304152534\n",
      "RMSE Test: 19.311\n",
      "NRMSE Test: 0.9261210826210826\n",
      "------------------\n",
      "Model threshold\n",
      "R^2 Complete: 0.22343987998731252\n",
      "RMSE Complete: 4.686\n",
      "NRMSE Complete: 0.3806435615618184\n",
      "R^2 Train: 0.21561548741643843\n",
      "RMSE Train: 4.591\n",
      "NRMSE Train: 0.37572869722756924\n",
      "RMSE Test: 10.741\n",
      "NRMSE Test: 0.5151191832858499\n",
      "------------------\n",
      "Model df\n",
      "R^2 Complete: 0.35005215672583756\n",
      "RMSE Complete: 4.795\n",
      "NRMSE Complete: 0.42486640661791497\n",
      "R^2 Train: 0.34717491988702487\n",
      "RMSE Train: 4.701\n",
      "NRMSE Train: 0.4201813794289957\n",
      "RMSE Test: 11.137\n",
      "NRMSE Test: 0.534110636277303\n",
      "------------------\n",
      "Model hss\n",
      "R^2 Complete: 0.4404995269556562\n",
      "RMSE Complete: 4.157\n",
      "NRMSE Complete: 1.2367470386659831\n",
      "R^2 Train: 0.41909334421220956\n",
      "RMSE Train: 4.012\n",
      "NRMSE Train: 1.2539293377199254\n",
      "RMSE Test: 14.928\n",
      "NRMSE Test: 0.715920227920228\n",
      "------------------\n",
      "Model polya\n",
      "R^2 Complete: 0.30157109098729296\n",
      "RMSE Complete: 4.728\n",
      "NRMSE Complete: 0.41356315924877796\n",
      "R^2 Train: 0.29768183635553325\n",
      "RMSE Train: 4.635\n",
      "NRMSE Train: 0.4086861754694191\n",
      "RMSE Test: 11.244\n",
      "NRMSE Test: 0.5392421652421653\n",
      "------------------\n",
      "Model recast\n",
      "R^2 Complete: 0.22666267739438184\n",
      "RMSE Complete: 7.044\n",
      "NRMSE Complete: 0.5138471931050547\n",
      "R^2 Train: 0.2188115885495875\n",
      "RMSE Train: 6.84\n",
      "NRMSE Train: 0.5141856925418569\n",
      "RMSE Test: 10.826\n",
      "NRMSE Test: 0.5191956315289649\n"
     ]
    }
   ],
   "source": [
    "dict_results = {}\n",
    "dict_misinformation = {}\n",
    "dict_msg = {}\n",
    "list_features = ['u_first_nb', 'v_first_nb', 'u_n_gini_count',\n",
    "       'v_n_gini_count', 'u_n_unique_group', 'v_n_unique_group',\n",
    "       'Common_n_group', 'u_n_unique_msg', 'v_n_unique_msg', 'u_n_total_msg',\n",
    "       'v_n_total_msg']\n",
    "\n",
    "\n",
    "for model, parameter in dict_models.items():\n",
    "    if model == \"Original\":\n",
    "        PATH_Regression = 'WhatsApp/regression/'+k+'-'+str(parameter)\n",
    "    else:\n",
    "        PATH_Regression = 'WhatsApp/regression/'+k+'-'+str(parameter)+'-'\n",
    "\n",
    "    print(\"------------------\")\n",
    "    print(\"Model\", model)\n",
    "    dict_results[model] = []\n",
    "    edge_list = pkl.load(open(PATH_Regression+'edge_list_'+model+'.pickle', 'rb'))\n",
    "    X = np.sqrt(edge_list[list_features]) \n",
    "    Y = np.sqrt(edge_list['w'])\n",
    "    model_1, model_2 = compute_regression(X, Y)\n",
    "    edge_list['y'] = Y\n",
    "    edge_list['y_hat'] = model_2.predict(X) \n",
    "    edge_list['res'] = (Y-edge_list['y_hat'])\n",
    "    print('R^2 Complete:', model_2.score(X, Y))\n",
    "    dict_results[model].append((\"R^2 Train\", model_2.score(X, Y)))\n",
    "    RMSE = round(sklearn.metrics.mean_squared_error(edge_list['y']**2, edge_list['y_hat']**2, squared=False),3)\n",
    "    print(\"RMSE Complete:\", RMSE)\n",
    "    print(\"NRMSE Complete:\", RMSE/np.mean(edge_list['w']))\n",
    "    \n",
    "    def count_msg_mis(df_full, list_nodes):\n",
    "        df_temp = df_full[df_full['User_ID'].isin(list_nodes)]\n",
    "        n_miss = len(df_temp[df_temp['Misinformation'] == 1])\n",
    "        n_msg = len(df_temp)\n",
    "        return n_miss, n_msg\n",
    "    \n",
    "    list_nodes = set(edge_list['u']).union(edge_list['v'])\n",
    "\n",
    "    #Train and test \n",
    "    idx_test = pkl.load(open('WhatsApp/regression/'+k+'-'+'set_common_edge_test.pickle', 'rb'))\n",
    "    idx_test = pd.MultiIndex.from_tuples(idx_test, names=['u', 'v'])\n",
    "    edge_list = edge_list.set_index(['u','v'])\n",
    "    edge_list_test = edge_list.loc[idx_test].reset_index(drop=False)\n",
    "    edge_list = edge_list.drop(idx_test)\n",
    "\n",
    "\n",
    "    X = np.sqrt(edge_list[list_features]) \n",
    "    Y = np.sqrt(edge_list['w'])\n",
    "    model_1, model_2 = compute_regression(X, Y)\n",
    "    edge_list['y'] = Y\n",
    "    edge_list['y_hat'] = model_2.predict(X) \n",
    "    edge_list['res'] = (Y-edge_list['y_hat'])\n",
    "    print('R^2 Train:', model_2.score(X, Y))\n",
    "    dict_results[model].append((\"R^2 Train\", model_2.score(X, Y)))\n",
    "    RMSE = round(sklearn.metrics.mean_squared_error(edge_list['y']**2, edge_list['y_hat']**2, squared=False),3)\n",
    "    print(\"RMSE Train:\", RMSE)\n",
    "    print(\"NRMSE Train:\", RMSE/np.mean(edge_list['w']))\n",
    "\n",
    "    X = np.sqrt(edge_list_test[list_features])\n",
    "    Y = np.sqrt(edge_list_test['w'])\n",
    "    edge_list_test['y'] = Y\n",
    "    edge_list_test['y_hat'] = model_2.predict(X)\n",
    "    edge_list_test['res'] = (Y-edge_list_test['y_hat'])\n",
    "    RMSE = round(sklearn.metrics.mean_squared_error(edge_list_test['y']**2, edge_list_test['y_hat']**2, squared=False),3)\n",
    "    print(\"RMSE Test:\", RMSE)\n",
    "    print(\"NRMSE Test:\", RMSE/np.mean(edge_list_test['w']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "rational-christianity",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
